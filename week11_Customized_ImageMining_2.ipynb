{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7211c184",
      "metadata": {
        "id": "7211c184"
      },
      "source": [
        "# Hands-on Session for Customized Image Mining 2\n",
        "\n",
        "Credit to: [Youngeui Kim](https://cis.appstate.edu/directory/youngeui-kim-phd), [Yuxiao (Rain) Luo](https://yuxiaoluo.github.io)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YuxiaoLuo/AI_Intro/blob/main/week11_Customized_ImageMining_2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3562b9",
      "metadata": {
        "id": "fe3562b9"
      },
      "source": [
        "## Step 1: Create your folders and save image data respectively\n",
        "\n",
        "- create train data directories\n",
        "- create validation data directories\n",
        "\n",
        "See the graph below:\n",
        "```\n",
        "/train/\n",
        "    /Positive/\n",
        "        positive1.jpeg\n",
        "        positive2.jpeg\n",
        "    /Negative/\n",
        "        negative1.jpeg\n",
        "        negative2.jpeg\n",
        "/val/\n",
        "    /Positive/\n",
        "        positive1.jpeg\n",
        "        positive2.jpeg\n",
        "    /Negative/\n",
        "        negative1.jpeg\n",
        "        negative2.jpeg\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca531e6",
      "metadata": {
        "id": "9ca531e6"
      },
      "source": [
        "- Download the files needed for model training: https://github.com/YuxiaoLuo/AI_Intro/tree/main/data/customized_image_mining"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8925929",
      "metadata": {
        "id": "b8925929"
      },
      "source": [
        "If you are using Google Colab, mount your google drive to Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e0313b",
      "metadata": {
        "id": "37e0313b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651e64f5",
      "metadata": {
        "id": "651e64f5"
      },
      "source": [
        "## Step 2: Data loading and Data Generating diversifying"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42f56fd",
      "metadata": {
        "id": "a42f56fd"
      },
      "source": [
        "- If you are using Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02444f2",
      "metadata": {
        "id": "a02444f2"
      },
      "outputs": [],
      "source": [
        "# Define data paths\n",
        "train_dir = '/content/drive/MyDrive/train'\n",
        "val_dir = '/content/drive/MyDrive/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41cbb58",
      "metadata": {
        "id": "b41cbb58"
      },
      "source": [
        "- If you run it locally, change your folder path accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c8a0bd",
      "metadata": {
        "id": "68c8a0bd"
      },
      "outputs": [],
      "source": [
        "# Define data paths\n",
        "train_dir = '/data/customized_image_mining/train'\n",
        "val_dir = '/data/customized_image_mining/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5883c1f8",
      "metadata": {
        "id": "5883c1f8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,  # Use VGG16 preprocessing\n",
        "    rotation_range=30,                        # Augmentation: Random rotations\n",
        "    width_shift_range=0.2,                    # Augmentation: Horizontal shifts\n",
        "    height_shift_range=0.2,                   # Augmentation: Vertical shifts\n",
        "    shear_range=0.2,                          # Augmentation: Shearing\n",
        "    zoom_range=0.2,                           # Augmentation: Zooming\n",
        "    horizontal_flip=True,                     # Augmentation: Flipping\n",
        "    fill_mode='nearest'                       # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Load data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),                   # Resize images to 224x224 (VGG16 input size)\n",
        "    batch_size=32,                            # Number of images per batch\n",
        "    class_mode='categorical'                  # Labels are categorical\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Check the classes\n",
        "print(train_generator.class_indices)  # {'Negative': 0, 'Positive': 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9402b69a",
      "metadata": {
        "id": "9402b69a"
      },
      "source": [
        "## Step 3: Customize the VGG16 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672ff45f",
      "metadata": {
        "id": "672ff45f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load VGG16 base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
        "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
        "predictions = Dense(2, activation='softmax')(x)  # Output layer with 2 classes\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc0adf0",
      "metadata": {
        "id": "2fc0adf0"
      },
      "source": [
        "## Step 4: Train the Custom Layers & Save the customized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd096d26",
      "metadata": {
        "id": "bd096d26"
      },
      "outputs": [],
      "source": [
        "# Data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/custom_vgg16_sentiment_model.h5')\n",
        "Step 5-1: Applying the Customized Model to Your Data\n",
        "--- Once trained, we can apply the model as follows:\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the customized model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/custom_vgg16_sentiment_model.h5')\n",
        "\n",
        "# Function to preprocess and predict\n",
        "def predict_sentiment(img_path):\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(np.expand_dims(img_array, axis=0))\n",
        "    prediction = model.predict(img_array)\n",
        "    sentiment_labels = ['Negative', 'Positive']\n",
        "    return sentiment_labels[np.argmax(prediction)], np.max(prediction)\n",
        "\n",
        "\n",
        "# Predict on a new (individual) image\n",
        "sentiment, confidence = predict_sentiment('/content/drive/MyDrive/Colab Notebooks/image.jpg')\n",
        "print(f\"Sentiment: {sentiment}, Confidence: {confidence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f2e245",
      "metadata": {
        "id": "94f2e245"
      },
      "source": [
        "## Step 5-2 (1) : Applying the Customized Model to Your Bulk Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd51fc2b",
      "metadata": {
        "id": "cd51fc2b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Load the customized model\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/custom_vgg16_sentiment_model.h5')\n",
        "\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(img_path):\n",
        "    img = load_img(img_path, target_size=(224, 224))  # Resize image to 224x224\n",
        "    img_array = img_to_array(img)                     # Convert to array\n",
        "    img_array = preprocess_input(np.expand_dims(img_array, axis=0))  # Preprocess for VGG16\n",
        "    prediction = model.predict(img_array)             # Predict with the model\n",
        "    sentiment_labels = ['Negative', 'Positive']       # Define labels\n",
        "    return sentiment_labels[np.argmax(prediction)], np.max(prediction)  # Return sentiment and confidence\n",
        "\n",
        "\n",
        "# checking the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ReviewData_updated.csv', encoding='ISO-8859-1')\n",
        "filtered_data = df.dropna(subset=['Image'])\n",
        "filtered_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4d62138",
      "metadata": {
        "id": "a4d62138"
      },
      "source": [
        "## Step 5-2 (2) : Applying the Customized Model to Your Bulk Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9417a896",
      "metadata": {
        "id": "9417a896",
        "outputId": "a841b8fc-91fa-4390-c666-4da5197d6577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3958e8364cfb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load image metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/ReviewData_updated.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfiltered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# load my data to predict\n",
        "if __name__ == \"__main__\":\n",
        "    # Load image metadata\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ReviewData_updated.csv', encoding='ISO-8859-1')\n",
        "    filtered_data = df.dropna(subset=['Image'])\n",
        "\n",
        "    # Initialize variables for results\n",
        "    sentiment_counts = {'Negative': 0, 'Positive': 0}\n",
        "    predicted_sentiments = []\n",
        "    image_names = []\n",
        "    confidences = []\n",
        "\n",
        "    # Process each image\n",
        "    for index, row in filtered_data.iterrows():\n",
        "        image_name = str(int(row['Image']))\n",
        "        img_path = f'/content/drive/MyDrive/Colab Notebooks/bulk/{image_name}.jpeg'\n",
        "\n",
        "        try:\n",
        "            # Predict sentiment for the image\n",
        "            sentiment, confidence = predict_sentiment(img_path)\n",
        "\n",
        "            # Store results\n",
        "            predicted_sentiments.append(sentiment)\n",
        "            image_names.append(image_name)\n",
        "            confidences.append(confidence)\n",
        "\n",
        "            # Update sentiment counts\n",
        "            if sentiment in sentiment_counts:\n",
        "                sentiment_counts[sentiment] += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_name}: {e}\")\n",
        "\n",
        "    # Print sentiment counts\n",
        "    print(\"Sentiment Counts:\")\n",
        "    for sentiment, count in sentiment_counts.items():\n",
        "        print(f\"{sentiment}: {count}\")\n",
        "\n",
        "    # Create a results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'image_name': image_names,\n",
        "        'predicted_sentiment': predicted_sentiments,\n",
        "        'confidence': confidences\n",
        "    })\n",
        "\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv('/content/drive/MyDrive/Colab Notebooks/ReviewData_updated_With_Image.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e61d6b7",
      "metadata": {
        "id": "5e61d6b7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}